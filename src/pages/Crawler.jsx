export default function Crawler() {
  return (
    <div>
      <h2 className="text-3xl font-bold mb-6 text-pokeYellow">Crawler (Python)</h2>

      <p className="mb-4">
        O servi√ßo de <strong>crawler</strong> √© respons√°vel por obter dados da <a href="https://pokeapi.co/" target="_blank" className="text-blue-600 hover:underline">Pok√©API</a> e inseri-los na base de dados PostgreSQL da aplica√ß√£o.
        Foi desenvolvido em Python, utilizando as bibliotecas <code>requests</code> para consumo da API e <code>psycopg2</code> para liga√ß√£o √† base de dados.
      </p>

      <p className="mb-4">
        O crawler recolhe os primeiros 151 Pok√©mons, extrai os seus detalhes principais (nome, ID, tipos, imagem e URL da API) e insere os dados na base de dados da aplica√ß√£o.
      </p>

      <p className="font-semibold mb-2">‚öôÔ∏è Fluxo de funcionamento:</p>
      <ol className="list-decimal pl-6 mb-6">
        <li>Recolha da lista de Pok√©mons</li>
        <li>Requisi√ß√£o individual de cada Pok√©mon para obter detalhes</li>
        <li>Processamento e estrutura√ß√£o dos dados</li>
        <li>Inser√ß√£o em batch na base de dados PostgreSQL</li>
      </ol>

      <p className="mb-2 font-semibold">üß† Fun√ß√µes principais:</p>

      <p className="mb-1"><code>get_pokemon_list()</code> ‚Äî Obt√©m os primeiros 151 Pok√©mons da Pok√©API:</p>
      <pre className="bg-gray-100 p-4 rounded text-sm overflow-x-auto mb-4">
{`def get_pokemon_list():
    next_url = f"{BASE_URL}/pokemon?limit=151"
    response = requests.get(next_url)
    data = response.json()
    return data["results"]`}
      </pre>

      <p className="mb-1"><code>get_pokemon_details(name, url)</code> ‚Äî Vai buscar os dados detalhados de cada Pok√©mon:</p>
      <pre className="bg-gray-100 p-4 rounded text-sm overflow-x-auto mb-4">
{`type_primary = pokemon["types"][0]["type"]["name"]
type_secondary = pokemon["types"][1]["type"]["name"] if len(pokemon["types"]) > 1 else None`}
      </pre>

      <p className="mb-1"><code>insert_pokemon_data(pokemons)</code> ‚Äî Insere todos os registos na base de dados:</p>
      <pre className="bg-gray-100 p-4 rounded text-sm overflow-x-auto mb-4">
{`INSERT INTO pokemons (id, name, type_primary, type_secondary, url, sprite)
VALUES (%s, %s, %s, %s, %s, %s)
ON CONFLICT (id) DO NOTHING`}
      </pre>

      <p className="mb-4">
        A execu√ß√£o do crawler √© feita automaticamente atrav√©s de um <strong>cron job</strong> configurado no sistema operativo. Este processo garante a actualiza√ß√£o regular dos dados, sem necessidade de interven√ß√£o manual.
      </p>

      <p className="mb-4">
        O script √© invocado com o comando:
      </p>

      <pre className="bg-gray-100 p-4 rounded text-sm overflow-x-auto mb-6">
{`python3 /home/ubuntu/pokecrawler/crawler/crawler.py`}
      </pre>

      <p className="mb-4">
        A linha correspondente no ficheiro <code>crontab</code> pode ser, por exemplo:
      </p>

      <pre className="bg-gray-100 p-4 rounded text-sm overflow-x-auto mb-6">
{`0 */6 * * * python3 /home/ubuntu/pokecrawler/crawler/crawler.py >> /var/log/pokecrawler.log 2>&1`}
      </pre>

      <p>
        Esta configura√ß√£o executa o script de 6 em 6 horas e guarda os registos de execu√ß√£o num ficheiro local. Todas as mensagens s√£o tratadas com a biblioteca <code>logging</code>, facilitando o diagn√≥stico em caso de falhas.
      </p>
    </div>
  );
}
